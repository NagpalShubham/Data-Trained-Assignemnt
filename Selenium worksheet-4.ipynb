{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0b5d76",
   "metadata": {},
   "source": [
    "# Scrape the details of most viewed videos on YouTube from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccfdd741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e80844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\dell\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ade303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2276c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list for scraping data\n",
    "Rank =[]\n",
    "Name =[]\n",
    "Artist =[]\n",
    "Upload_date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cce8642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Rank Via X path\n",
    "try:\n",
    "    rank=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Rank.append('NA')\n",
    "    \n",
    "# Extracting Name Via X path\n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Name.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Name.append('NA')\n",
    "    \n",
    "# Extracting Artist Name Via Xpath\n",
    "try:\n",
    "    artist=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "    for i in artist:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Artist.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Artist.append('NA')\n",
    "\n",
    "# Extracting Upload date Via Xpath\n",
    "try:\n",
    "    upload_date=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "    for i in upload_date:\n",
    "        Upload_date.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Upload_date.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Upload_date.append('NA') \n",
    "\n",
    "# Extracting Views via Xpath\n",
    "try:\n",
    "    views=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "    for i in views:\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Views.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Views.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67fe4b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMost Viewed Video on YouTube from Wikipedia :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Uploader</th>\n",
       "      <th>Views (in Billons)</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[3]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>11.24</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[6]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.96</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[12]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.44</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[13]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.80</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[15]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.62</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Bath Song\"[20]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>5.59</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[21]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>4.85</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[22]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.68</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[23]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.61</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Gangnam Style\"[24]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.53</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[29]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.51</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Wheels on the Bus\"[30]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.31</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[31]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.05</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[32]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[33]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.64</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[34]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.63</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Sorry\"[35]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.58</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Axel F\"[36]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.49</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"[37]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.49</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[38]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.35</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.34</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[40]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.33</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[41]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.33</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[42]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.29</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Bailando\"[43]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.26</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Lean On\"[44]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.25</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"[45]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.24</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[46]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.23</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shake It Off\"[47]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.20</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.14</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Video Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[3]   \n",
       "1    2.                                   \"Despacito\"[6]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[12]   \n",
       "3    4.                               \"Shape of You\"[13]   \n",
       "4    5.                              \"See You Again\"[15]   \n",
       "5    6.                                  \"Bath Song\"[20]   \n",
       "6    7.                \"Phonics Song with Two Words\"[21]   \n",
       "7    8.                                \"Uptown Funk\"[22]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[23]   \n",
       "9   10.                              \"Gangnam Style\"[24]   \n",
       "10  11.   \"Masha and the Bear – Recipe for Disaster\"[29]   \n",
       "11  12.                          \"Wheels on the Bus\"[30]   \n",
       "12  13.                             \"Dame Tu Cosita\"[31]   \n",
       "13  14.                                      \"Sugar\"[32]   \n",
       "14  15.                                       \"Roar\"[33]   \n",
       "15  16.                             \"Counting Stars\"[34]   \n",
       "16  17.                                      \"Sorry\"[35]   \n",
       "17  18.                                     \"Axel F\"[36]   \n",
       "18  18.                          \"Thinking Out Loud\"[37]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[38]   \n",
       "20  21.                                 \"Dark Horse\"[39]   \n",
       "21  22.                                      \"Faded\"[40]   \n",
       "22  23.                             \"Girls Like You\"[41]   \n",
       "23  24.                                 \"Let Her Go\"[42]   \n",
       "24  25.                                   \"Bailando\"[43]   \n",
       "25  26.                                    \"Lean On\"[44]   \n",
       "26  27.                                    \"Perfect\"[45]   \n",
       "27  28.           \"Waka Waka (This Time for Africa)\"[46]   \n",
       "28  29.                               \"Shake It Off\"[47]   \n",
       "29  30.          \"Humpty the train on a fruits ride\"[48]   \n",
       "\n",
       "                                         Uploader Views (in Billons)  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories              11.24   \n",
       "1                                      Luis Fonsi               7.96   \n",
       "2                                     LooLoo Kids               6.44   \n",
       "3                                      Ed Sheeran               5.80   \n",
       "4                                     Wiz Khalifa               5.62   \n",
       "5                      Cocomelon – Nursery Rhymes               5.59   \n",
       "6                                       ChuChu TV               4.85   \n",
       "7                                     Mark Ronson               4.68   \n",
       "8                                     Miroshka TV               4.61   \n",
       "9                                             Psy               4.53   \n",
       "10                                     Get Movies               4.51   \n",
       "11                     Cocomelon – Nursery Rhymes               4.31   \n",
       "12                                      El Chombo               4.05   \n",
       "13                                       Maroon 5               3.75   \n",
       "14                                     Katy Perry               3.64   \n",
       "15                                    OneRepublic               3.63   \n",
       "16                                  Justin Bieber               3.58   \n",
       "17                                     Crazy Frog               3.49   \n",
       "18                                     Ed Sheeran               3.49   \n",
       "19                     Cocomelon – Nursery Rhymes               3.35   \n",
       "20                                     Katy Perry               3.34   \n",
       "21                                    Alan Walker               3.33   \n",
       "22                                       Maroon 5               3.33   \n",
       "23                                      Passenger               3.29   \n",
       "24                               Enrique Iglesias               3.26   \n",
       "25                                    Major Lazer               3.25   \n",
       "26                                     Ed Sheeran               3.24   \n",
       "27                                        Shakira               3.23   \n",
       "28                                   Taylor Swift               3.20   \n",
       "29  Kiddiestv Hindi – Nursery Rhymes & Kids Songs               3.14   \n",
       "\n",
       "          Upload Date  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3    January 30, 2017  \n",
       "4       April 6, 2015  \n",
       "5         May 2, 2018  \n",
       "6       March 6, 2014  \n",
       "7   November 19, 2014  \n",
       "8   February 27, 2018  \n",
       "9       July 15, 2012  \n",
       "10   January 31, 2012  \n",
       "11       May 24, 2018  \n",
       "12      April 5, 2018  \n",
       "13   January 14, 2015  \n",
       "14  September 5, 2013  \n",
       "15       May 31, 2013  \n",
       "16   October 22, 2015  \n",
       "17      June 16, 2009  \n",
       "18    October 7, 2014  \n",
       "19      June 25, 2018  \n",
       "20  February 20, 2014  \n",
       "21   December 3, 2015  \n",
       "22       May 31, 2018  \n",
       "23      July 25, 2012  \n",
       "24     April 11, 2014  \n",
       "25     March 22, 2015  \n",
       "26   November 9, 2017  \n",
       "27       June 4, 2010  \n",
       "28    August 18, 2014  \n",
       "29   January 26, 2018  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for scrap data\n",
    "Wiki_YT=pd.DataFrame({'Rank':Rank,'Video Name':Name,'Uploader':Artist,'Views (in Billons)':Views,'Upload Date':Upload_date})\n",
    "print('\\033[1m'+'Most Viewed Video on YouTube from Wikipedia :'+'\\033[0m')\n",
    "Wiki_YT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0907f36",
   "metadata": {},
   "source": [
    "# Q2 - Scrape the details team India’s international fixtures from bcci.tv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669fe0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.bcci.tv/international/fixtures\"\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bbc0a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ['England Women', 'India Women', 'England Women', 'India Women', 'England Women', 'India Women', 'India', 'Australia', 'England Women', 'India Women', 'India', 'Australia', 'England Women', 'India Women', 'India', 'Australia']\n"
     ]
    }
   ],
   "source": [
    "Team=[]\n",
    "Date_Time =[]\n",
    "Ground=[]\n",
    "Test_ODI=[]\n",
    "#scraping the team_name \n",
    "tm=driver.find_elements(By.XPATH,'//h5[@class=\"country-name ng-binding\"]')\n",
    "for i in tm:\n",
    "    if i.text is None :\n",
    "        Team.append(\"--\") \n",
    "    else:\n",
    "        Team.append(i.text)\n",
    "print(len(Team),Team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97ccba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 ['13 SEP 2022', '15 SEP 2022', '18 SEP 2022', '20 SEP 2022', '21 SEP 2022', '23 SEP 2022', '24 SEP 2022', '25 SEP 2022']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Date_Time \n",
    "DT=driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]')\n",
    "for i in DT:\n",
    "    if i.text is None :\n",
    "        Date_Time.append(\"--\") \n",
    "    else:\n",
    "        Date_Time.append(i.text)\n",
    "print(len(Date_Time),Date_Time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03e1277c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 ['2nd T20I - County Ground, Derby', '3rd T20I - County Ground, Bristol', '1st ODI - County Ground, Hove', '1st T20I - Punjab Cricket Association IS Bindra Stadium, Mohali', '2nd ODI - St Lawrence Ground, Canterbury', '2nd T20I - Vidarbha Cricket Association Stadium, Nagpur', \"3rd ODI - Lord's Cricket Ground, London\", '3rd T20I - Rajiv Gandhi International Stadium, Hyderabad']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Ground \n",
    "G=driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "for i in G:\n",
    "    if i.text is None :\n",
    "        Ground.append(\"--\") \n",
    "    else:\n",
    "        Ground.append(i.text)\n",
    "print(len(Ground),Ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc9f9a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 ['INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022', 'INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022', 'INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022', 'AUSTRALIA TOUR OF INDIA T20 SERIES 2022', 'INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022', 'AUSTRALIA TOUR OF INDIA T20 SERIES 2022', 'INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022', 'AUSTRALIA TOUR OF INDIA T20 SERIES 2022']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Test_ODI \n",
    "TO=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "for i in TO:\n",
    "    if i.text is None :\n",
    "        Test_ODI.append(\"--\") \n",
    "    else:\n",
    "        Test_ODI.append(i.text)\n",
    "print(len(Test_ODI),Test_ODI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45197f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Series</th>\n",
       "      <th>Ground</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022</td>\n",
       "      <td>2nd T20I - County Ground, Derby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022</td>\n",
       "      <td>3rd T20I - County Ground, Bristol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022</td>\n",
       "      <td>1st ODI - County Ground, Hove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>1st T20I - Punjab Cricket Association IS Bindr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022</td>\n",
       "      <td>2nd ODI - St Lawrence Ground, Canterbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>2nd T20I - Vidarbha Cricket Association Stadiu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022</td>\n",
       "      <td>3rd ODI - Lord's Cricket Ground, London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>3rd T20I - Rajiv Gandhi International Stadium,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date_Time                                       Series  \\\n",
       "0        NaN  INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022   \n",
       "1        NaN  INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022   \n",
       "2        NaN  INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022   \n",
       "3        NaN      AUSTRALIA TOUR OF INDIA T20 SERIES 2022   \n",
       "4        NaN  INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022   \n",
       "5        NaN      AUSTRALIA TOUR OF INDIA T20 SERIES 2022   \n",
       "6        NaN  INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022   \n",
       "7        NaN      AUSTRALIA TOUR OF INDIA T20 SERIES 2022   \n",
       "\n",
       "                                              Ground  \n",
       "0                    2nd T20I - County Ground, Derby  \n",
       "1                  3rd T20I - County Ground, Bristol  \n",
       "2                      1st ODI - County Ground, Hove  \n",
       "3  1st T20I - Punjab Cricket Association IS Bindr...  \n",
       "4           2nd ODI - St Lawrence Ground, Canterbury  \n",
       "5  2nd T20I - Vidarbha Cricket Association Stadiu...  \n",
       "6            3rd ODI - Lord's Cricket Ground, London  \n",
       "7  3rd T20I - Rajiv Gandhi International Stadium,...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "International_Fixtures=pd.DataFrame([])\n",
    "International_Fixtures['Date_Time']=Date_Time\n",
    "International_Fixtures['Series']=Test_ODI\n",
    "International_Fixtures['Ground']=Ground\n",
    "International_Fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f9dca",
   "metadata": {},
   "source": [
    "# Q3Scrape the details of selenium exception from guru99.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed87786",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_3=\"https://www.guru99.com/exception-handling-selenium.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a872980",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55a6168",
   "metadata": {},
   "outputs": [],
   "source": [
    "exception=[]\n",
    "description =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc1067e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n"
     ]
    }
   ],
   "source": [
    "#scraping the exception \n",
    "ex=driver.find_elements(By.XPATH,\"/html/body/div[2]/section[3]/div/div[1]/main/div[1]/div/div/div/div/div/div[2]/table/tbody/tr/td[1]\")\n",
    "for i in ex:\n",
    "    if i.text is None :\n",
    "        exception.append(\"--\") \n",
    "    else:\n",
    "        exception.append(i.text)\n",
    "print(len(exception),exception)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455970ac",
   "metadata": {},
   "source": [
    "# Q4Scrape the details of State-wise GDP of India from statisticstime.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45be2f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_4=\"http://statisticstimes.com/\"\n",
    "driver.get(url_4)\n",
    "Rank=[]\n",
    "State =[]\n",
    "GDP=[]\n",
    "GSDP_Current=[]\n",
    "GSDP_Previous=[]\n",
    "Share=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25539332",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy = driver.find_element(By.XPATH,'//*[@id=\"top\"]/div[2]/div[2]/button')       # Locating page foe top videos by xpath\n",
    "economy.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b774529",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = driver.find_element(By.XPATH,'//*[@id=\"top\"]/div[2]/div[2]/div/a[3]')       # Locating page foe top videos by xpath\n",
    "ind.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "582b1ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')       # Locating page foe top videos by xpath\n",
    "gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b72934c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Rank \n",
    "r=driver.find_elements(By.XPATH,\"//td[@class='data1']\")\n",
    "for i in r:\n",
    "    if i.text is None :\n",
    "        Rank.append(\"--\") \n",
    "    else:\n",
    "        Rank.append(i.text)\n",
    "print(len(Rank),Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9224fbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 ['Maharashtra', 'Tamil Nadu', 'Uttar Pradesh', 'Gujarat', 'Karnataka', 'West Bengal', 'Rajasthan', 'Andhra Pradesh', 'Telangana', 'Madhya Pradesh', 'Kerala', 'Delhi', 'Haryana', 'Bihar', 'Punjab', 'Odisha', 'Assam', 'Chhattisgarh', 'Jharkhand', 'Uttarakhand', 'Jammu & Kashmir', 'Himachal Pradesh', 'Goa', 'Tripura', 'Chandigarh', 'Puducherry', 'Meghalaya', 'Sikkim', 'Manipur', 'Nagaland', 'Arunachal Pradesh', 'Mizoram', 'Andaman & Nicobar Islands', 'India', 'Maharashtra', 'Tamil Nadu', 'Uttar Pradesh', 'Karnataka', 'Gujarat', 'West Bengal', 'Rajasthan', 'Telangana', 'Andhra Pradesh', 'Madhya Pradesh', 'Kerala', 'Delhi', 'Haryana', 'Bihar', 'Punjab', 'Odisha', 'Assam', 'Jharkhand', 'Chhattisgarh', 'Uttarakhand', 'Himachal Pradesh', 'Jammu & Kashmir', 'Goa', 'Tripura', 'Chandigarh', 'Puducherry', 'Meghalaya', 'Manipur', 'Sikkim', 'Nagaland', 'Arunachal Pradesh', 'Mizoram', 'Andaman & Nicobar Islands', 'India']\n"
     ]
    }
   ],
   "source": [
    "#scraping the State \n",
    "St=driver.find_elements(By.XPATH,\"//td[@class='name']\")\n",
    "for i in St:\n",
    "    if i.text is None :\n",
    "        State.append(\"--\") \n",
    "    else:\n",
    "        State.append(i.text)\n",
    "print(len(State),State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5ce5d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['399.921', '247.629', '240.726', '228.290', '226.806', '165.556', '143.179', '131.083', '130.791', '122.977', '118.733', '117.703', '111.519', '80.562', '79.957', '74.098', '47.982', '46.187', '45.145', '37.351', '23.690', '23.369', '11.115', '7.571', '6.397', '5.230', '5.086', '4.363', '4.233', '4.144', '3.737', '3.385', '-']\n"
     ]
    }
   ],
   "source": [
    "#scraping the GDP \n",
    "gdp=driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[6]\")\n",
    "for i in gdp:\n",
    "    if i.text is None :\n",
    "        GDP.append(\"--\") \n",
    "    else:\n",
    "        GDP.append(i.text)\n",
    "print(len(GDP),GDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13f383fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['13.94%', '8.63%', '8.39%', '7.96%', '7.91%', '5.77%', '4.99%', '4.57%', '4.56%', '4.29%', '4.14%', '4.10%', '3.89%', '2.81%', '2.79%', '2.58%', '1.67%', '1.61%', '1.57%', '1.30%', '0.83%', '0.81%', '0.39%', '0.26%', '0.22%', '0.18%', '0.18%', '0.15%', '0.15%', '0.14%', '0.13%', '0.12%', '-']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Share \n",
    "shr=driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[5]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        Share.append(\"--\") \n",
    "    else:\n",
    "        Share.append(i.text)\n",
    "print(len(Share),Share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ed27c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['2,632,792', '1,630,208', '1,584,764', '1,502,899', '1,493,127', '1,089,898', '942,586', '862,957', '861,031', '809,592', '781,653', '774,870', '734,163', '530,363', '526,376', '487,805', '315,881', '304,063', '297,204', '245,895', '155,956', '153,845', '73,170', '49,845', '42,114', '34,433', '33,481', '28,723', '27,870', '27,283', '24,603', '22,287', '-']\n"
     ]
    }
   ],
   "source": [
    "#scraping the GSDP_Current \n",
    "shr=driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[4]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        GSDP_Current.append(\"--\") \n",
    "    else:\n",
    "        GSDP_Current.append(i.text)\n",
    "print(len(GSDP_Current),GSDP_Current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c04ced6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['2,039,074', '1,215,307', '1,123,982', '1,186,379', '1,091,077', '739,525', '677,428', '621,301', '612,828', '522,009', '559,412', '590,569', '531,085', '375,651', '397,669', '376,877', '234,048', '231,182', '224,986', '193,273', '112,755', '117,851', '57,787', '36,963', '31,192', '23,013', '24,682', '18,722', '19,300', '17,647', '16,676', '16,478', '-']\n"
     ]
    }
   ],
   "source": [
    "#scraping the GSDP_Previous \n",
    "shr=driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[8]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        GSDP_Previous.append(\"--\") \n",
    "    else:\n",
    "        GSDP_Previous.append(i.text)\n",
    "print(len(GSDP_Previous),GSDP_Previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7051bbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>Share In GDP</th>\n",
       "      <th>GDP of State</th>\n",
       "      <th>GSDP_Current</th>\n",
       "      <th>GSDP_Previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>2,039,074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,215,307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,123,982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>1,186,379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,091,077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>739,525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "      <td>942,586</td>\n",
       "      <td>677,428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "      <td>862,957</td>\n",
       "      <td>621,301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "      <td>861,031</td>\n",
       "      <td>612,828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "      <td>809,592</td>\n",
       "      <td>522,009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "      <td>781,653</td>\n",
       "      <td>559,412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "      <td>774,870</td>\n",
       "      <td>590,569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "      <td>734,163</td>\n",
       "      <td>531,085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "      <td>530,363</td>\n",
       "      <td>375,651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "      <td>526,376</td>\n",
       "      <td>397,669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "      <td>487,805</td>\n",
       "      <td>376,877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "      <td>315,881</td>\n",
       "      <td>234,048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "      <td>304,063</td>\n",
       "      <td>231,182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "      <td>297,204</td>\n",
       "      <td>224,986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "      <td>245,895</td>\n",
       "      <td>193,273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "      <td>155,956</td>\n",
       "      <td>112,755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "      <td>153,845</td>\n",
       "      <td>117,851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "      <td>73,170</td>\n",
       "      <td>57,787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "      <td>49,845</td>\n",
       "      <td>36,963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "      <td>42,114</td>\n",
       "      <td>31,192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "      <td>34,433</td>\n",
       "      <td>23,013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "      <td>33,481</td>\n",
       "      <td>24,682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "      <td>28,723</td>\n",
       "      <td>18,722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "      <td>27,870</td>\n",
       "      <td>19,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "      <td>27,283</td>\n",
       "      <td>17,647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "      <td>24,603</td>\n",
       "      <td>16,676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "      <td>22,287</td>\n",
       "      <td>16,478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State Share In GDP GDP of State GSDP_Current  \\\n",
       "0     1                Maharashtra       13.94%      399.921    2,632,792   \n",
       "1     2                 Tamil Nadu        8.63%      247.629    1,630,208   \n",
       "2     3              Uttar Pradesh        8.39%      240.726    1,584,764   \n",
       "3     4                    Gujarat        7.96%      228.290    1,502,899   \n",
       "4     5                  Karnataka        7.91%      226.806    1,493,127   \n",
       "5     6                West Bengal        5.77%      165.556    1,089,898   \n",
       "6     7                  Rajasthan        4.99%      143.179      942,586   \n",
       "7     8             Andhra Pradesh        4.57%      131.083      862,957   \n",
       "8     9                  Telangana        4.56%      130.791      861,031   \n",
       "9    10             Madhya Pradesh        4.29%      122.977      809,592   \n",
       "10   11                     Kerala        4.14%      118.733      781,653   \n",
       "11   12                      Delhi        4.10%      117.703      774,870   \n",
       "12   13                    Haryana        3.89%      111.519      734,163   \n",
       "13   14                      Bihar        2.81%       80.562      530,363   \n",
       "14   15                     Punjab        2.79%       79.957      526,376   \n",
       "15   16                     Odisha        2.58%       74.098      487,805   \n",
       "16   17                      Assam        1.67%       47.982      315,881   \n",
       "17   18               Chhattisgarh        1.61%       46.187      304,063   \n",
       "18   19                  Jharkhand        1.57%       45.145      297,204   \n",
       "19   20                Uttarakhand        1.30%       37.351      245,895   \n",
       "20   21            Jammu & Kashmir        0.83%       23.690      155,956   \n",
       "21   22           Himachal Pradesh        0.81%       23.369      153,845   \n",
       "22   23                        Goa        0.39%       11.115       73,170   \n",
       "23   24                    Tripura        0.26%        7.571       49,845   \n",
       "24   25                 Chandigarh        0.22%        6.397       42,114   \n",
       "25   26                 Puducherry        0.18%        5.230       34,433   \n",
       "26   27                  Meghalaya        0.18%        5.086       33,481   \n",
       "27   28                     Sikkim        0.15%        4.363       28,723   \n",
       "28   29                    Manipur        0.15%        4.233       27,870   \n",
       "29   30                   Nagaland        0.14%        4.144       27,283   \n",
       "30   31          Arunachal Pradesh        0.13%        3.737       24,603   \n",
       "31   32                    Mizoram        0.12%        3.385       22,287   \n",
       "32   33  Andaman & Nicobar Islands            -            -            -   \n",
       "\n",
       "   GSDP_Previous  \n",
       "0      2,039,074  \n",
       "1      1,215,307  \n",
       "2      1,123,982  \n",
       "3      1,186,379  \n",
       "4      1,091,077  \n",
       "5        739,525  \n",
       "6        677,428  \n",
       "7        621,301  \n",
       "8        612,828  \n",
       "9        522,009  \n",
       "10       559,412  \n",
       "11       590,569  \n",
       "12       531,085  \n",
       "13       375,651  \n",
       "14       397,669  \n",
       "15       376,877  \n",
       "16       234,048  \n",
       "17       231,182  \n",
       "18       224,986  \n",
       "19       193,273  \n",
       "20       112,755  \n",
       "21       117,851  \n",
       "22        57,787  \n",
       "23        36,963  \n",
       "24        31,192  \n",
       "25        23,013  \n",
       "26        24,682  \n",
       "27        18,722  \n",
       "28        19,300  \n",
       "29        17,647  \n",
       "30        16,676  \n",
       "31        16,478  \n",
       "32             -  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "State_GDP=pd.DataFrame([])\n",
    "State_GDP['Rank']=Rank[:33]\n",
    "State_GDP['State']=State[:33]\n",
    "State_GDP['Share In GDP']=Share[:33]\n",
    "State_GDP['GDP of State']=GDP[:33]\n",
    "State_GDP['GSDP_Current']=GSDP_Current[:33]\n",
    "State_GDP['GSDP_Previous']=GSDP_Previous[:33]\n",
    "State_GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d49785",
   "metadata": {},
   "source": [
    "# Q5 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9a7fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_5=\"https://github.com/\"\n",
    "driver.get(url_5)\n",
    "Repository_Name =[]\n",
    "Language=[]\n",
    "Muted_Link=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ab535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore = driver.find_element(By.XPATH,'//a[@class=\"js-selected-navigation-item selected Header-link mt-md-n3 mb-md-n3 py-2 py-md-3 mr-0 mr-md-3 border-top border-md-top-0 border-white-fade\"]')       # Locating page foe top videos by xpath\n",
    "explore.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf460a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending = driver.find_element(By.XPATH,'//a[@class=\"js-selected-navigation-item d-inline-block py-2 py-md-3 mr-3 mr-md-4 no-underline subnav-link\"]')       # Locating page foe top videos by xpath\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bc33224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['danielgindi /', 'surrealdb /', 'TheAlgorithms /', 'SerenityOS /', 'divamgupta /', 'karpathy /', 'EbookFoundation /', 'twitter /', 'n8n-io /', 'InterviewReady /', 'moby /', 'Alamofire /', 'AykutSarac /', 'pocketbase /', 'ascoders /', 'jellyfin /', 'apptension /', 'vasanthk /', 'rust-lang /', 'dotnet /', 'microsoft /', 'gothinkster /', 'SerenityOS /', 'jwasham /', 'joeyballentine /']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Repositor_Name \n",
    "RN=driver.find_elements(By.XPATH,\"//span[@class='text-normal']\")\n",
    "for i in RN:\n",
    "    if i.text is None :\n",
    "        Repository_Name.append(\"--\") \n",
    "    else:\n",
    "        Repository_Name.append(i.text)\n",
    "print(len(Repository_Name),Repository_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cab0d82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['Beautiful charts for iOS/tvOS/OSX! The Apple side of the crossplatform MPAndroidChart.', 'A scalable, distributed, collaborative, document-graph database, for the realtime web', 'All Algorithms implemented in Python', 'Ladybird web browser', 'Diffusion Bee is the easiest way to run Stable Diffusion locally on your M1 Mac. Comes with a one-click installer. No dependencies or technical knowledge needed.', 'Neural Networks: Zero to Hero', '📚 Freely available programming books', 'Static checks to aid with a healthy adoption of Compose', 'Free and source-available fair-code licensed workflow automation tool. Easily automate tasks across different services.', 'These are the best resources for System Design on the Internet', 'Moby Project - a collaborative project for the container ecosystem to assemble container-based systems', 'Elegant HTTP Networking in Swift', '🔮 Seamlessly visualize your JSON data instantly into graphs; paste, import or fetch!', 'Open Source realtime backend in 1 file', '前端精读周刊。帮你理解最前沿、实用的技术。', 'The Free Software Media System', 'An opinionated guide on how to become a professional Web/Mobile App Developer.', 'What happens behind the scenes when we type www.google.com in a browser?', 'Empowering everyone to build reliable and efficient software.', 'Home repository for .NET Core', 'Playwright is a framework for Web Testing and Automation. It allows testing Chromium, Firefox and WebKit with a single API.', '\"The mother of all demo apps\" — Exemplary fullstack Medium.com clone powered by React, Angular, Node, Django, and many more 🏅', 'The Serenity Operating System 🐞', 'A complete computer science study plan to become a software engineer.', 'A flowchart/node-based image processing GUI aimed at making chaining image processing tasks (especially upscaling done by neural networks) easy, intuitive, and customizable.']\n"
     ]
    }
   ],
   "source": [
    "Description=[]\n",
    "#scraping the Description \n",
    "des=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in des:\n",
    "    if i.text is None :\n",
    "        Description.append(\"--\") \n",
    "    else:\n",
    "        Description.append(i.text)\n",
    "print(len(Description),Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "563f453d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 ['Swift', 'Rust', 'Python', 'C++', 'Jupyter Notebook', 'Jupyter Notebook', 'Kotlin', 'TypeScript', 'Go', 'Swift', 'TypeScript', 'Go', 'JavaScript', 'C#', 'Rust', 'PowerShell', 'TypeScript', 'Shell', 'C++', 'TypeScript']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Language \n",
    "L=driver.find_elements(By.XPATH,\"//span[@itemprop='programmingLanguage']\")\n",
    "for i in L:\n",
    "    if i.text is None :\n",
    "        Language.append(\"NAN\") \n",
    "    else:\n",
    "        Language.append(i.text)\n",
    "print(len(Language),Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d5cc4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trending_Repository=pd.DataFrame([])\n",
    "Trending_Repository['Name']=Repository_Name[:20]\n",
    "Trending_Repository['Description']=Description[:20]\n",
    "Trending_Repository['Language']=Language[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8e2f147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>danielgindi /</td>\n",
       "      <td>Beautiful charts for iOS/tvOS/OSX! The Apple s...</td>\n",
       "      <td>Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surrealdb /</td>\n",
       "      <td>A scalable, distributed, collaborative, docume...</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheAlgorithms /</td>\n",
       "      <td>All Algorithms implemented in Python</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SerenityOS /</td>\n",
       "      <td>Ladybird web browser</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>divamgupta /</td>\n",
       "      <td>Diffusion Bee is the easiest way to run Stable...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>karpathy /</td>\n",
       "      <td>Neural Networks: Zero to Hero</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EbookFoundation /</td>\n",
       "      <td>📚 Freely available programming books</td>\n",
       "      <td>Kotlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>twitter /</td>\n",
       "      <td>Static checks to aid with a healthy adoption o...</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n8n-io /</td>\n",
       "      <td>Free and source-available fair-code licensed w...</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InterviewReady /</td>\n",
       "      <td>These are the best resources for System Design...</td>\n",
       "      <td>Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>moby /</td>\n",
       "      <td>Moby Project - a collaborative project for the...</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Alamofire /</td>\n",
       "      <td>Elegant HTTP Networking in Swift</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AykutSarac /</td>\n",
       "      <td>🔮 Seamlessly visualize your JSON data instantl...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pocketbase /</td>\n",
       "      <td>Open Source realtime backend in 1 file</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ascoders /</td>\n",
       "      <td>前端精读周刊。帮你理解最前沿、实用的技术。</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jellyfin /</td>\n",
       "      <td>The Free Software Media System</td>\n",
       "      <td>PowerShell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>apptension /</td>\n",
       "      <td>An opinionated guide on how to become a profes...</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vasanthk /</td>\n",
       "      <td>What happens behind the scenes when we type ww...</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rust-lang /</td>\n",
       "      <td>Empowering everyone to build reliable and effi...</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dotnet /</td>\n",
       "      <td>Home repository for .NET Core</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name                                        Description  \\\n",
       "0       danielgindi /  Beautiful charts for iOS/tvOS/OSX! The Apple s...   \n",
       "1         surrealdb /  A scalable, distributed, collaborative, docume...   \n",
       "2     TheAlgorithms /               All Algorithms implemented in Python   \n",
       "3        SerenityOS /                               Ladybird web browser   \n",
       "4        divamgupta /  Diffusion Bee is the easiest way to run Stable...   \n",
       "5          karpathy /                      Neural Networks: Zero to Hero   \n",
       "6   EbookFoundation /               📚 Freely available programming books   \n",
       "7           twitter /  Static checks to aid with a healthy adoption o...   \n",
       "8            n8n-io /  Free and source-available fair-code licensed w...   \n",
       "9    InterviewReady /  These are the best resources for System Design...   \n",
       "10             moby /  Moby Project - a collaborative project for the...   \n",
       "11        Alamofire /                   Elegant HTTP Networking in Swift   \n",
       "12       AykutSarac /  🔮 Seamlessly visualize your JSON data instantl...   \n",
       "13       pocketbase /             Open Source realtime backend in 1 file   \n",
       "14         ascoders /                              前端精读周刊。帮你理解最前沿、实用的技术。   \n",
       "15         jellyfin /                     The Free Software Media System   \n",
       "16       apptension /  An opinionated guide on how to become a profes...   \n",
       "17         vasanthk /  What happens behind the scenes when we type ww...   \n",
       "18        rust-lang /  Empowering everyone to build reliable and effi...   \n",
       "19           dotnet /                      Home repository for .NET Core   \n",
       "\n",
       "            Language  \n",
       "0              Swift  \n",
       "1               Rust  \n",
       "2             Python  \n",
       "3                C++  \n",
       "4   Jupyter Notebook  \n",
       "5   Jupyter Notebook  \n",
       "6             Kotlin  \n",
       "7         TypeScript  \n",
       "8                 Go  \n",
       "9              Swift  \n",
       "10        TypeScript  \n",
       "11                Go  \n",
       "12        JavaScript  \n",
       "13                C#  \n",
       "14              Rust  \n",
       "15        PowerShell  \n",
       "16        TypeScript  \n",
       "17             Shell  \n",
       "18               C++  \n",
       "19        TypeScript  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trending_Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771c8214",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of top 100 songs on billiboard.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4c18704",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_6=\"https://www.billboard.com/\"\n",
    "driver.get(url_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0cc6237",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song_Name =[]\n",
    "Singer=[]\n",
    "rank=[]\n",
    "Last_Week=[]\n",
    "Weeks_on_board=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4892347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top100 = driver.find_element(By.XPATH,'//a[@class=\"c-link  lrv-a-unstyle-link lrv-u-color-brand-primary:hover lrv-a-hover-effect lrv-u-whitespace-nowrap lrv-u-color-grey-dark\"]')       # Locating page foe top videos by xpath\n",
    "top100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f0782c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Rank \n",
    "rb=driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-bold-l u-font-size-32@tablet u-letter-spacing-0080@tablet\"]')\n",
    "for i in rb:\n",
    "    if i.text is None :\n",
    "        rank.append(\"--\") \n",
    "    else:\n",
    "        rank.append(i.text)\n",
    "print(len(rank),rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b926617a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 ['Bad Habit\\nSteve Lacy', 'Late Night Talking\\nHarry Styles', 'Sunroof\\nNicky Youre & dazy', 'About Damn Time\\nLizzo', 'I Like You (A Happier Song)\\nPost Malone Featuring Doja Cat', 'Super Freaky Girl\\nNicki Minaj', \"I Ain't Worried\\nOneRepublic\", 'Running Up That Hill (A Deal With God)\\nKate Bush', 'You Proof\\nMorgan Wallen', 'Wait For U\\nFuture Featuring Drake & Tems', 'Me Porto Bonito\\nBad Bunny & Chencho Corleone', 'Titi Me Pregunto\\nBad Bunny', 'The Kind Of Love We Make\\nLuke Combs', 'Break My Soul\\nBeyonce', 'First Class\\nJack Harlow', 'Wasted On You\\nMorgan Wallen', 'Heat Waves\\nGlass Animals', 'She Had Me At Heads Carolina\\nCole Swindell', 'Vegas\\nDoja Cat', 'Jimmy Cooks\\nDrake Featuring 21 Savage', 'Stay\\nThe Kid LAROI & Justin Bieber', 'Hold Me Closer\\nElton John & Britney Spears', '5 Foot 9\\nTyler Hubbard', 'Detox\\nLil Baby', 'Glimpse Of Us\\nJoji', 'Last Night Lonely\\nJon Pardi', 'Moscow Mule\\nBad Bunny', 'Big Energy\\nLatto', 'Staying Alive\\nDJ Khaled Featuring Drake & Lil Baby', 'Betty (Get Money)\\nYung Gravy', 'Something In The Orange\\nZach Bryan', 'Ghost\\nJustin Bieber', 'Shivers\\nEd Sheeran', 'In A Minute\\nLil Baby', 'Rock And A Hard Place\\nBailey Zimmerman', 'Left And Right\\nCharlie Puth Featuring Jung Kook', 'Efecto\\nBad Bunny', 'Son Of A Sinner\\nJelly Roll', 'Numb\\nMarshmello & Khalid', 'Fall In Love\\nBailey Zimmerman', 'Talk\\nYeat', 'God Did\\nDJ Khaled Featuring Rick Ross, Lil Wayne, JAY-Z, John Legend & Fridayy', 'Provenza\\nKarol G', 'Unstoppable\\nSia', \"I'm Good (Blue)\\nDavid Guetta & Bebe Rexha\", 'Numb Little Bug\\nEm Beihold', 'Bones\\nImagine Dragons', 'Dah Dah DahDah\\nNardo Wick', 'Victoria’s Secret\\nJax', 'Gatubela\\nKarol G x Maldy', 'Die For You\\nThe Weeknd', 'Last Last\\nBurna Boy', 'Truth About You\\nMitchell Tenpenny', 'Hot Shit\\nCardi B, Ye & Lil Durk', 'Free Mind\\nTems', 'Sleazy Flow\\nSleazyWorld Go Featuring Lil Baby', 'So Good\\nHalsey', 'With A Woman You Love\\nJustin Moore', 'Like I Love Country Music\\nKane Brown', 'Wishful Drinking\\nIngrid Andress With Sam Hunt', 'Party\\nBad Bunny & Rauw Alejandro', 'Despecha\\nRosalia', \"F.N.F. (Let's Go)\\nHitkidd & GloRilla\", 'Golden Hour\\nJVKE', 'Ojitos Lindos\\nBad Bunny & Bomba Estereo', 'Pink Venom\\nBLACKPINK', 'Beat The Odds\\nLil Tjay', 'Sticky\\nDrake', 'Pick Me Up\\nGabby Barrett', 'Whiskey On You\\nNate Smith', 'Despues de La Playa\\nBad Bunny', 'Beautiful\\nDJ Khaled Featuring Future & SZA', 'She Likes It\\nRussell Dickerson & Jake Scott', 'Until I Found You\\nStephen Sanchez', 'Ghost Story\\nCarrie Underwood', 'Romantic Homicide\\nd4vd', '2 Be Loved (Am I Ready)\\nLizzo', 'Where It Ends\\nBailey Zimmerman', 'Alone\\nRod Wave', 'Neverita\\nBad Bunny', 'All Mine\\nBrent Faiyaz', 'Tarot\\nBad Bunny & Jhay Cortez', 'What My World Spins Around\\nJordan Davis', 'Half Of Me\\nThomas Rhett Featuring Riley Green', 'La Bachata\\nManuel Turizo', 'Music For A Sushi Restaurant\\nHarry Styles', \"Don't Come Lookin'\\nJackson Dean\", 'Soul\\nLee Brice', 'Bad Decisions\\nbenny blanco, BTS & Snoop Dogg', 'Calm Down\\nRema & Selena Gomez', 'Puffin On Zootiez\\nFuture', 'Snap\\nRosa Linn', 'Hotel Lobby (Unc And Phew)\\nQuavo & Takeoff', 'Bzrp Music Sessions, Vol. 52\\nBizarrap & Quevedo', 'Thought You Should Know\\nMorgan Wallen', 'Country On\\nLuke Bryan', 'Static\\nSteve Lacy', 'Billie Eilish.\\nArmani White', 'Sin Fin\\nRomeo Santos & Justin Timberlake']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Song_Name \n",
    "son=driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // lrv-u-flex-grow-1 lrv-u-flex lrv-u-flex-direction-column lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light lrv-u-padding-l-050 lrv-u-padding-l-1@mobile-max\"]')\n",
    "for i in son:\n",
    "    if i.text is None :\n",
    "        Song_Name.append(\"--\") \n",
    "    else:\n",
    "        Song_Name.append(i.text)\n",
    "print(len(Song_Name),Song_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da6946ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594 ['2', '2', '10', '', '', '', '12', '3', '16', '', '', '', '5', '4', '15', '', '', '', '3', '1', '21', '', '', '', '8', '6', '14', '', '', '', '7', '1', '4', '', '', '', '14', '8', '13', '', '', '', '4', '3', '35', '', '', '', '13', '6', '17', '', '', '', '10', '1', '19', '', '', '', '11', '6', '18', '', '', '', '16', '5', '18', '', '', '', '15', '13', '12', '', '', '', '9', '1', '12', '', '', '', '18', '1', '22', '', '', '', '20', '9', '43', '', '', '', '19', '1', '86', '', '', '', '22', '18', '15', '', '', '', '25', '20', '14', '', '', '', '23', '1', '12', '', '', '', '24', '1', '61', '', '', '', '6', '6', '2', '', '', '', '28', '24', '13', '', '', '', '-', '25', '1', '', '', '', '26', '8', '13', '', '', '', '27', '27', '15', '', '', '', '30', '4', '18', '', '', '', '32', '3', '46', '', '', '', '21', '5', '5', '', '', '', '33', '31', '9', '', '', '', '42', '30', '20', '', '', '', '34', '5', '50', '', '', '', '35', '4', '52', '', '', '', '40', '14', '22', '', '', '', '38', '24', '13', '', '', '', '47', '22', '11', '', '', '', '39', '34', '18', '', '', '', '43', '39', '10', '', '', '', '44', '40', '10', '', '', '', '45', '31', '19', '', '', '', '-', '42', '1', '', '', '', '17', '17', '2', '', '', '', '46', '25', '20', '', '', '', '50', '45', '10', '', '', '', '81', '46', '2', '', '', '', '48', '18', '32', '', '', '', '58', '48', '16', '', '', '', '54', '48', '6', '', '', '', '59', '50', '6', '', '', '', '37', '37', '2', '', '', '', '69', '43', '6', '', '', '', '67', '53', '9', '', '', '', '70', '54', '8', '', '', '', '60', '13', '10', '', '', '', '61', '56', '8', '', '', '', '62', '47', '15', '', '', '', '63', '54', '13', '', '', '', '64', '59', '7', '', '', '', '52', '26', '16', '', '', '', '51', '51', '10', '', '', '', '65', '14', '18', '', '', '', '75', '63', '5', '', '', '', '73', '49', '15', '', '', '', '71', '65', '2', '', '', '', '68', '26', '18', '', '', '', '53', '22', '3', '', '', '', '36', '36', '2', '', '', '', '56', '6', '12', '', '', '', '80', '69', '7', '', '', '', '82', '65', '12', '', '', '', '74', '6', '18', '', '', '', '29', '29', '2', '', '', '', '84', '63', '23', '', '', '', '87', '75', '10', '', '', '', '85', '61', '16', '', '', '', '-', '77', '1', '', '', '', '97', '78', '4', '', '', '', '72', '32', '3', '', '', '', '76', '21', '4', '', '', '', '79', '31', '9', '', '', '', '88', '42', '5', '', '', '', '83', '18', '18', '', '', '', '93', '84', '4', '', '', '', '92', '85', '3', '', '', '', '95', '86', '3', '', '', '', '-', '8', '8', '', '', '', '-', '88', '2', '', '', '', '-', '89', '2', '', '', '', '89', '10', '5', '', '', '', '-', '91', '1', '', '', '', '91', '4', '19', '', '', '', '-', '93', '2', '', '', '', '94', '59', '15', '', '', '', '100', '82', '5', '', '', '', '96', '12', '18', '', '', '', '-', '76', '3', '', '', '', '-', '98', '1', '', '', '', '-', '99', '1', '', '', '', '-', '100', '1', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Last_Week Rank \n",
    "lwr=driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max\"]')\n",
    "for i in lwr:\n",
    "    if i.text is None :\n",
    "        Last_Week.append(\"--\") \n",
    "    else:\n",
    "        Last_Week.append(i.text)\n",
    "print(len(Last_Week),Last_Week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cc192fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Last_Week_Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bad Habit\\nSteve Lacy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Late Night Talking\\nHarry Styles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Sunroof\\nNicky Youre &amp; dazy</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>About Damn Time\\nLizzo</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I Like You (A Happier Song)\\nPost Malone Featu...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>Thought You Should Know\\nMorgan Wallen</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Country On\\nLuke Bryan</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Static\\nSteve Lacy</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Billie Eilish.\\nArmani White</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Sin Fin\\nRomeo Santos &amp; Justin Timberlake</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Peak_rank                                          Song_Name Last_Week_Rank\n",
       "0          1                              Bad Habit\\nSteve Lacy              2\n",
       "1          2                   Late Night Talking\\nHarry Styles              2\n",
       "2          3                        Sunroof\\nNicky Youre & dazy             10\n",
       "3          4                             About Damn Time\\nLizzo               \n",
       "4          5  I Like You (A Happier Song)\\nPost Malone Featu...               \n",
       "..       ...                                                ...            ...\n",
       "94        95             Thought You Should Know\\nMorgan Wallen               \n",
       "95        96                             Country On\\nLuke Bryan               \n",
       "96        97                                 Static\\nSteve Lacy             19\n",
       "97        98                       Billie Eilish.\\nArmani White              1\n",
       "98        99          Sin Fin\\nRomeo Santos & Justin Timberlake             86\n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_Song=pd.DataFrame([])\n",
    "Top_Song['Peak_rank']=rank[0:99]\n",
    "Top_Song['Song_Name']=Song_Name[0:99]\n",
    "Top_Song['Last_Week_Rank']=Last_Week[0:99]\n",
    "Top_Song"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7de9768",
   "metadata": {},
   "source": [
    "# Scrape the details of Data science recruiters from naukri.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "93878f8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//a[@title='Search Recruiters']\"}\n  (Session info: chrome=105.0.5195.102)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x003E78B3+2193587]\n\tOrdinal0 [0x00380681+1771137]\n\tOrdinal0 [0x002941A8+803240]\n\tOrdinal0 [0x002C24A0+992416]\n\tOrdinal0 [0x002C273B+993083]\n\tOrdinal0 [0x002EF7C2+1177538]\n\tOrdinal0 [0x002DD7F4+1103860]\n\tOrdinal0 [0x002EDAE2+1170146]\n\tOrdinal0 [0x002DD5C6+1103302]\n\tOrdinal0 [0x002B77E0+948192]\n\tOrdinal0 [0x002B86E6+952038]\n\tGetHandleVerifier [0x00690CB2+2738370]\n\tGetHandleVerifier [0x006821B8+2678216]\n\tGetHandleVerifier [0x004717AA+512954]\n\tGetHandleVerifier [0x00470856+509030]\n\tOrdinal0 [0x0038743B+1799227]\n\tOrdinal0 [0x0038BB68+1817448]\n\tOrdinal0 [0x0038BC55+1817685]\n\tOrdinal0 [0x00395230+1856048]\n\tBaseThreadInitThunk [0x75F1FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77B87B5E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77B87B2E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8476/4226193656.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Clicking on recuriters option\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mrecruiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"//a[@title='Search Recruiters']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecruiters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    853\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    856\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    430\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//a[@title='Search Recruiters']\"}\n  (Session info: chrome=105.0.5195.102)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x003E78B3+2193587]\n\tOrdinal0 [0x00380681+1771137]\n\tOrdinal0 [0x002941A8+803240]\n\tOrdinal0 [0x002C24A0+992416]\n\tOrdinal0 [0x002C273B+993083]\n\tOrdinal0 [0x002EF7C2+1177538]\n\tOrdinal0 [0x002DD7F4+1103860]\n\tOrdinal0 [0x002EDAE2+1170146]\n\tOrdinal0 [0x002DD5C6+1103302]\n\tOrdinal0 [0x002B77E0+948192]\n\tOrdinal0 [0x002B86E6+952038]\n\tGetHandleVerifier [0x00690CB2+2738370]\n\tGetHandleVerifier [0x006821B8+2678216]\n\tGetHandleVerifier [0x004717AA+512954]\n\tGetHandleVerifier [0x00470856+509030]\n\tOrdinal0 [0x0038743B+1799227]\n\tOrdinal0 [0x0038BB68+1817448]\n\tOrdinal0 [0x0038BC55+1817685]\n\tOrdinal0 [0x00395230+1856048]\n\tBaseThreadInitThunk [0x75F1FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77B87B5E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77B87B2E+238]\n"
     ]
    }
   ],
   "source": [
    "# Opening Wikipedia webpage\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "# Clicking on recuriters option\n",
    "recruiters=driver.find_element(By.XPATH,\"//a[@title='Search Recruiters']\")\n",
    "driver.get(recruiters.get_attribute('href'))\n",
    "time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b47fb36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating Search bar via Xpath\n",
    "Search=driver.find_element(By.XPATH,'//input[@class=\"suggestor-input \"]')\n",
    "\n",
    "# Sending data science as key in search bar\n",
    "Search.send_keys(\"Data Science\")\n",
    "time.sleep(1)\n",
    "\n",
    "#clicking on search button\n",
    "button=driver.find_element(By.XPATH,'//div[@class=\"qsbSubmit\"]')\n",
    "button.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "680d3050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List\n",
    "Name =[]\n",
    "Designation =[]\n",
    "Company =[]\n",
    "Skill =[]\n",
    "Location =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb29db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping  Name\n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH,'//a[@class=\"ellipsis\"]/span')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "        Name.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b0548ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(Name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a87c9e",
   "metadata": {},
   "source": [
    "# Q8Scrape the details of Highest selling novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7133025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Wikipedia webpage\n",
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aacbf996",
   "metadata": {},
   "outputs": [],
   "source": [
    "Book =[]\n",
    "Author =[]\n",
    "Volumes_sold =[]\n",
    "Publisher =[]\n",
    "Genre =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a80bd53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Book name\n",
    "try:\n",
    "    book=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "    for i in book:\n",
    "        Book.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Book.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "337ba99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    author=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "    for i in author:\n",
    "        Author.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Author.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc21e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sold=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "    for i in sold:\n",
    "        Volumes_sold.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Volumes_sold.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5de26dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    publisher=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for i in publisher:\n",
    "        Publisher.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Publisher.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07991072",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    genre=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c417aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBest Selling Books of All Time List by The Guardian  :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Book Title       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "Top_Books=pd.DataFrame({\"Book Title\":Book,\n",
    "                \"Author Name\":Author,\n",
    "                'Volumes sold':Volumes_sold,\n",
    "                'Publisher':Publisher,\n",
    "                'Genre':Genre})\n",
    "print('\\033[1m'+'Best Selling Books of All Time List by The Guardian  :'+'\\033[0m')\n",
    "Top_Books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930c6a61",
   "metadata": {},
   "source": [
    "# Q9 - Scrape the details most watched tv series of all time from imdb.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ea1b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Wikipedia webpage\n",
    "url='https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c2c6ad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List\n",
    "Name =[]\n",
    "Year_Span=[]\n",
    "Genre =[]\n",
    "Run_Time =[]\n",
    "Ratings =[]\n",
    "Votes =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "153fb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    year=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/span[2]\")\n",
    "    for i in year:\n",
    "        Year_Span.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Year_Span.append('NA')\n",
    "    \n",
    "# Scraping Genre via Xpath\n",
    "try:\n",
    "    genre=driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('NA')\n",
    "    \n",
    "# Scraping RunTime via Xpath\n",
    "try:\n",
    "    runtime=driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "    for i in runtime:\n",
    "        Run_Time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Run_Time.append('NA')\n",
    "\n",
    "# Scraping Ratings via Xpath\n",
    "try:\n",
    "    ratings=driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']/span[2]\")\n",
    "    for i in ratings:\n",
    "        Ratings.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Ratings.append('NA')\n",
    "\n",
    "# Scraping Votes via Xpath\n",
    "try:\n",
    "    votes=driver.find_elements(By.XPATH,\"//span[@name='nv']\")\n",
    "    for i in votes:\n",
    "        Votes.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Votes.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f178977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Name via Xpath\n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\")\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1890c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTop 100 most watched tv shows of all time IMDB :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,049,496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,145,373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>968,315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>288,837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>248,406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>49,560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>60,565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>194,788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>236,456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,049,496  \n",
       "1    51 min     8.7  1,145,373  \n",
       "2    44 min     8.1    968,315  \n",
       "3    60 min     7.5    288,837  \n",
       "4    43 min     7.6    248,406  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     49,560  \n",
       "96   50 min     7.8     60,565  \n",
       "97   42 min     8.1    194,788  \n",
       "98   45 min     7.1     41,022  \n",
       "99  572 min     8.6    236,456  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "IMDB_TV=pd.DataFrame({\"Name\":Name,\n",
    "                \"Year Span\":Year_Span,\n",
    "                \"Genre\":Genre,\n",
    "                \"Run Time\":Run_Time,\n",
    "                \"Ratings\":Ratings,\n",
    "                \"Votes\":Votes})\n",
    "print('\\033[1m'+'Top 100 most watched tv shows of all time IMDB :'+'\\033[0m')\n",
    "IMDB_TV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c728c9",
   "metadata": {},
   "source": [
    "# Q10 - Details of Datasets from UCI machine learning repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "07e53529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Wikipedia webpage\n",
    "url='https://archive.ics.uci.edu/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be08586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on all datasets links\n",
    "dataset=driver.find_element(By.XPATH,\"//a[@href='datasets.php']\")\n",
    "dataset.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f75d3975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists\n",
    "Dataset =[]\n",
    "Data_Type =[]\n",
    "Task =[]\n",
    "Attribute_Type =[]\n",
    "No_of_Instances =[]\n",
    "No_of_Attribute =[]\n",
    "Year =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9aa8124d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 622/622 [01:53<00:00,  5.48it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgumentException",
     "evalue": "Message: invalid argument: 'using' must be a string\n  (Session info: chrome=105.0.5195.102)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x003E78B3+2193587]\n\tOrdinal0 [0x00380681+1771137]\n\tOrdinal0 [0x002941A8+803240]\n\tOrdinal0 [0x002C2631+992817]\n\tOrdinal0 [0x002C273B+993083]\n\tOrdinal0 [0x002EF7FC+1177596]\n\tOrdinal0 [0x002DD7F4+1103860]\n\tOrdinal0 [0x002EDAE2+1170146]\n\tOrdinal0 [0x002DD5C6+1103302]\n\tOrdinal0 [0x002B77E0+948192]\n\tOrdinal0 [0x002B86E6+952038]\n\tGetHandleVerifier [0x00690CB2+2738370]\n\tGetHandleVerifier [0x006821B8+2678216]\n\tGetHandleVerifier [0x004717AA+512954]\n\tGetHandleVerifier [0x00470856+509030]\n\tOrdinal0 [0x0038743B+1799227]\n\tOrdinal0 [0x0038BB68+1817448]\n\tOrdinal0 [0x0038BC55+1817685]\n\tOrdinal0 [0x00395230+1856048]\n\tBaseThreadInitThunk [0x75F1FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77B87B5E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77B87B2E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8476/1203269936.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# Scraping No_of_Attribute via Xpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mno_of_Attribute\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;34m'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mno_of_Attribute\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mNo_of_Attribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Return empty list if driver returns null\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         return self.execute(Command.FIND_ELEMENTS, {\n\u001b[0m\u001b[0;32m    889\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m             'value': value})['value'] or []\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    430\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mInvalidArgumentException\u001b[0m: Message: invalid argument: 'using' must be a string\n  (Session info: chrome=105.0.5195.102)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x003E78B3+2193587]\n\tOrdinal0 [0x00380681+1771137]\n\tOrdinal0 [0x002941A8+803240]\n\tOrdinal0 [0x002C2631+992817]\n\tOrdinal0 [0x002C273B+993083]\n\tOrdinal0 [0x002EF7FC+1177596]\n\tOrdinal0 [0x002DD7F4+1103860]\n\tOrdinal0 [0x002EDAE2+1170146]\n\tOrdinal0 [0x002DD5C6+1103302]\n\tOrdinal0 [0x002B77E0+948192]\n\tOrdinal0 [0x002B86E6+952038]\n\tGetHandleVerifier [0x00690CB2+2738370]\n\tGetHandleVerifier [0x006821B8+2678216]\n\tGetHandleVerifier [0x004717AA+512954]\n\tGetHandleVerifier [0x00470856+509030]\n\tOrdinal0 [0x0038743B+1799227]\n\tOrdinal0 [0x0038BB68+1817448]\n\tOrdinal0 [0x0038BC55+1817685]\n\tOrdinal0 [0x00395230+1856048]\n\tBaseThreadInitThunk [0x75F1FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77B87B5E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77B87B2E+238]\n"
     ]
    }
   ],
   "source": [
    "# Scraping DataSet Name via Xpath\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    dataset=driver.find_elements(By.XPATH,\"//p[@class='normal']/b/a\")\n",
    "    for i in tqdm(dataset):\n",
    "        Dataset.append(i.text)\n",
    "        time.sleep(0.15)\n",
    "except NoSuchElementException:\n",
    "    Dataset.append('NA')\n",
    "    \n",
    "# Scraping Data Type via Xpath\n",
    "try:\n",
    "    Type=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]')\n",
    "    for i in Type[1:]:\n",
    "        Data_Type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Data_Type.append('NA')\n",
    "    \n",
    "# Scraping Task via Xpath\n",
    "try:\n",
    "    task=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]')\n",
    "    for i in task[1:]:\n",
    "        Task.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Task.append('NA')\n",
    "    \n",
    "# Scraping Attribute_Type via Xpath\n",
    "try:\n",
    "    attribute_Type=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]')\n",
    "    for i in attribute_Type[1:]:\n",
    "        Attribute_Type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Attribute_Type.append('NA')\n",
    "    \n",
    "# Scraping No_of_Instances via Xpath\n",
    "try:\n",
    "    no_of_Instances=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]')\n",
    "    for i in no_of_Instances[1:]:\n",
    "        No_of_Instances.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Instances.append('NA')\n",
    "\n",
    "# Scraping No_of_Attribute via Xpath\n",
    "try:\n",
    "    no_of_Attribute=driver.find_elements(By.XPATH<'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]')\n",
    "    for i in no_of_Attribute[1:]:\n",
    "        No_of_Attribute.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Attribute.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7099fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Year via Xpath\n",
    "try:\n",
    "    year=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]')\n",
    "    for i in year[1:]:\n",
    "        Year.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Year.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fcf17675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622, 622, 622, 622, 622, 622)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Dataset),len(Data_Type),len(Task),len(Attribute_Type),len(No_of_Instances),len(Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71e9ee39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m UCI Machine Learning Dataset:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSet Title</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         DataSet Title  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data Type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute Type No of Instances   Year  \n",
       "0    Categorical, Integer, Real            4177   1995   \n",
       "1          Categorical, Integer           48842   1996   \n",
       "2    Categorical, Integer, Real             798          \n",
       "3                   Categorical           37711   1998   \n",
       "4    Categorical, Integer, Real             452   1998   \n",
       "..                           ...             ...    ...  \n",
       "617               Integer, Real           75840   2020   \n",
       "618               Integer, Real             400   2020   \n",
       "619                                        1014   2020   \n",
       "620                        Real           10129   2021   \n",
       "621                        Real            4000   2021   \n",
       "\n",
       "[622 rows x 6 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame for UCI Dataset\n",
    "UCI_Dataset=pd.DataFrame({'DataSet Title':Dataset,\n",
    "                'Data Type':Data_Type,\n",
    "                'Task':Task,\n",
    "                'Attribute Type':Attribute_Type,\n",
    "                'No of Instances':No_of_Instances,\n",
    "                \n",
    "                'Year':Year})\n",
    "print('\\033[1m'+' UCI Machine Learning Dataset:'+'\\033[0m')\n",
    "UCI_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ada05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
